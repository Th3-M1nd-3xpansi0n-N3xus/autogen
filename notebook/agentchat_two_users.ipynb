{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/microsoft/autogen/blob/main/notebook/agentchat_two_users.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Auto Generated Agent Chat: Collaborative Task Solving with Multiple Agents and Human Users\n",
    "\n",
    "AutoGen offers conversable agents powered by LLM, tool, or human, which can be used to perform tasks collectively via automated chat. This framework allows tool use and human participation through multi-agent conversation. Please find documentation about this feature [here](https://microsoft.github.io/autogen/docs/Use-Cases/agent_chat).\n",
    "\n",
    "In this notebook, we demonstrate an application involving multiple agents and human users to work together and accomplish a task. `AssistantAgent` is an LLM-based agent that can write Python code (in a Python coding block) for a user to execute for a given task. `UserProxyAgent` is an agent which serves as a proxy for a user to execute the code written by `AssistantAgent`. We create multiple `UserProxyAgent` instances that can represent different human users.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "AutoGen requires `Python>=3.8`. To run this notebook example, please install:\n",
    "```bash\n",
    "pip install pyautogen\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-13T23:40:52.317406Z",
     "iopub.status.busy": "2023-02-13T23:40:52.316561Z",
     "iopub.status.idle": "2023-02-13T23:40:52.321193Z",
     "shell.execute_reply": "2023-02-13T23:40:52.320628Z"
    }
   },
   "outputs": [],
   "source": [
    "# %pip install pyautogen~=0.2.0b4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set your API Endpoint\n",
    "\n",
    "The [`config_list_from_json`](https://microsoft.github.io/autogen/docs/reference/oai/openai_utils#config_list_from_json) function loads a list of configurations from an environment variable or a json file.\n",
    "\n",
    "It first looks for an environment variable of a specified name (\"OAI_CONFIG_LIST\" in this example), which needs to be a valid json string. If that variable is not found, it looks for a json file with the same name. It filters the configs by models (you can filter by other keys as well).\n",
    "\n",
    "The json looks like the following:\n",
    "```json\n",
    "[\n",
    "    {\n",
    "        \"model\": \"gpt-4\",\n",
    "        \"api_key\": \"<your OpenAI API key here>\"\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"gpt-4\",\n",
    "        \"api_key\": \"<your Azure OpenAI API key here>\",\n",
    "        \"base_url\": \"<your Azure OpenAI API base here>\",\n",
    "        \"api_type\": \"azure\",\n",
    "        \"api_version\": \"2023-08-01-preview\"\n",
    "    },\n",
    "    {\n",
    "        \"model\": \"gpt-4-32k\",\n",
    "        \"api_key\": \"<your Azure OpenAI API key here>\",\n",
    "        \"base_url\": \"<your Azure OpenAI API base here>\",\n",
    "        \"api_type\": \"azure\",\n",
    "        \"api_version\": \"2023-08-01-preview\"\n",
    "    }\n",
    "]\n",
    "```\n",
    "\n",
    "You can set the value of config_list in any way you prefer. Please refer to this [notebook](https://github.com/microsoft/autogen/blob/main/notebook/oai_openai_utils.ipynb) for full code examples of the different methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen\n",
    "\n",
    "config_list = [\n",
    "    {\n",
    "        \"api_base\": \"http://0.0.0.0:8000\",\n",
    "    }\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct Agents\n",
    "\n",
    "We define `ask_expert` function to start a conversation between two agents and return a summary of the result. We construct an assistant agent named \"assistant_for_expert\" and a user proxy agent named \"expert\". We specify `human_input_mode` as \"ALWAYS\" in the user proxy agent, which will always ask for feedback from the expert user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_expert(message):\n",
    "    assistant_for_expert = autogen.AssistantAgent(\n",
    "        name=\"assistant_for_expert\",\n",
    "        llm_config={\n",
    "            \"temperature\": 0,\n",
    "            \"config_list\": config_list,\n",
    "        },\n",
    "    )\n",
    "    expert = autogen.UserProxyAgent(\n",
    "        name=\"expert\",\n",
    "        human_input_mode=\"ALWAYS\",\n",
    "        code_execution_config={\"work_dir\": \"expert\"},\n",
    "    )\n",
    "\n",
    "    expert.initiate_chat(assistant_for_expert, message=message)\n",
    "    expert.stop_reply_at_receive(assistant_for_expert)\n",
    "    # expert.human_input_mode, expert.max_consecutive_auto_reply = \"NEVER\", 0\n",
    "    # final message sent from the expert\n",
    "    expert.send(\"summarize the solution and explain the answer in an easy-to-understand way\", assistant_for_expert)\n",
    "    # return the last message the expert received\n",
    "    return expert.last_message()[\"content\"]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We construct another assistant agent named \"assistant_for_student\" and a user proxy agent named \"student\". We specify `human_input_mode` as \"TERMINATE\" in the user proxy agent, which will ask for feedback when it receives a \"TERMINATE\" signal from the assistant agent. We set the `functions` in `AssistantAgent` and `function_map` in `UserProxyAgent` to use the created `ask_expert` function.\n",
    "\n",
    "For simplicity, the `ask_expert` function is defined to run locally. For real applications, the function should run remotely to interact with an expert user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\MindExpander\\Documents\\GitHub\\autogen\\notebook\\agentchat_two_users.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/MindExpander/Documents/GitHub/autogen/notebook/agentchat_two_users.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m assistant_for_student \u001b[39m=\u001b[39m autogen\u001b[39m.\u001b[39;49mAssistantAgent(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MindExpander/Documents/GitHub/autogen/notebook/agentchat_two_users.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39massistant_for_student\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MindExpander/Documents/GitHub/autogen/notebook/agentchat_two_users.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     system_message\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mYou are a helpful assistant. Reply TERMINATE when the task is done.\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MindExpander/Documents/GitHub/autogen/notebook/agentchat_two_users.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     llm_config\u001b[39m=\u001b[39;49m{\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MindExpander/Documents/GitHub/autogen/notebook/agentchat_two_users.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mtimeout\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m600\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MindExpander/Documents/GitHub/autogen/notebook/agentchat_two_users.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mcache_seed\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m42\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MindExpander/Documents/GitHub/autogen/notebook/agentchat_two_users.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mconfig_list\u001b[39;49m\u001b[39m\"\u001b[39;49m: config_list,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MindExpander/Documents/GitHub/autogen/notebook/agentchat_two_users.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mtemperature\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m0\u001b[39;49m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MindExpander/Documents/GitHub/autogen/notebook/agentchat_two_users.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mfunctions\u001b[39;49m\u001b[39m\"\u001b[39;49m: [\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MindExpander/Documents/GitHub/autogen/notebook/agentchat_two_users.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m             {\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MindExpander/Documents/GitHub/autogen/notebook/agentchat_two_users.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mname\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mask_expert\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MindExpander/Documents/GitHub/autogen/notebook/agentchat_two_users.ipynb#X11sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mdescription\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mask expert when you can\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mt solve the problem satisfactorily.\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MindExpander/Documents/GitHub/autogen/notebook/agentchat_two_users.ipynb#X11sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m                 \u001b[39m\"\u001b[39;49m\u001b[39mparameters\u001b[39;49m\u001b[39m\"\u001b[39;49m: {\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MindExpander/Documents/GitHub/autogen/notebook/agentchat_two_users.ipynb#X11sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m                     \u001b[39m\"\u001b[39;49m\u001b[39mtype\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mobject\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MindExpander/Documents/GitHub/autogen/notebook/agentchat_two_users.ipynb#X11sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m                     \u001b[39m\"\u001b[39;49m\u001b[39mproperties\u001b[39;49m\u001b[39m\"\u001b[39;49m: {\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MindExpander/Documents/GitHub/autogen/notebook/agentchat_two_users.ipynb#X11sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m                         \u001b[39m\"\u001b[39;49m\u001b[39mmessage\u001b[39;49m\u001b[39m\"\u001b[39;49m: {\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MindExpander/Documents/GitHub/autogen/notebook/agentchat_two_users.ipynb#X11sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m                             \u001b[39m\"\u001b[39;49m\u001b[39mtype\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mstring\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MindExpander/Documents/GitHub/autogen/notebook/agentchat_two_users.ipynb#X11sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m                             \u001b[39m\"\u001b[39;49m\u001b[39mdescription\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39mquestion to ask expert. Ensure the question includes enough context, such as the code and the execution result. The expert does not know the conversation between you and the user unless you share the conversation with the expert.\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MindExpander/Documents/GitHub/autogen/notebook/agentchat_two_users.ipynb#X11sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m                         },\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MindExpander/Documents/GitHub/autogen/notebook/agentchat_two_users.ipynb#X11sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m                     },\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MindExpander/Documents/GitHub/autogen/notebook/agentchat_two_users.ipynb#X11sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m                     \u001b[39m\"\u001b[39;49m\u001b[39mrequired\u001b[39;49m\u001b[39m\"\u001b[39;49m: [\u001b[39m\"\u001b[39;49m\u001b[39mmessage\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MindExpander/Documents/GitHub/autogen/notebook/agentchat_two_users.ipynb#X11sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m                 },\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MindExpander/Documents/GitHub/autogen/notebook/agentchat_two_users.ipynb#X11sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m             }\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MindExpander/Documents/GitHub/autogen/notebook/agentchat_two_users.ipynb#X11sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m         ],\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MindExpander/Documents/GitHub/autogen/notebook/agentchat_two_users.ipynb#X11sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     }\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MindExpander/Documents/GitHub/autogen/notebook/agentchat_two_users.ipynb#X11sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MindExpander/Documents/GitHub/autogen/notebook/agentchat_two_users.ipynb#X11sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m student \u001b[39m=\u001b[39m autogen\u001b[39m.\u001b[39mUserProxyAgent(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MindExpander/Documents/GitHub/autogen/notebook/agentchat_two_users.ipynb#X11sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstudent\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MindExpander/Documents/GitHub/autogen/notebook/agentchat_two_users.ipynb#X11sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     human_input_mode\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTERMINATE\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MindExpander/Documents/GitHub/autogen/notebook/agentchat_two_users.ipynb#X11sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m     function_map\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mask_expert\u001b[39m\u001b[39m\"\u001b[39m: ask_expert},\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MindExpander/Documents/GitHub/autogen/notebook/agentchat_two_users.ipynb#X11sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\MindExpander\\Documents\\GitHub\\autogen\\.venv\\lib\\site-packages\\autogen\\agentchat\\assistant_agent.py:57\u001b[0m, in \u001b[0;36mAssistantAgent.__init__\u001b[1;34m(self, name, system_message, llm_config, is_termination_msg, max_consecutive_auto_reply, human_input_mode, code_execution_config, **kwargs)\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m     30\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m     31\u001b[0m     name: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m     39\u001b[0m ):\n\u001b[0;32m     40\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \u001b[39m        name (str): agent name.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[39m            [ConversableAgent](conversable_agent#__init__).\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 57\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\n\u001b[0;32m     58\u001b[0m         name,\n\u001b[0;32m     59\u001b[0m         system_message,\n\u001b[0;32m     60\u001b[0m         is_termination_msg,\n\u001b[0;32m     61\u001b[0m         max_consecutive_auto_reply,\n\u001b[0;32m     62\u001b[0m         human_input_mode,\n\u001b[0;32m     63\u001b[0m         code_execution_config\u001b[39m=\u001b[39mcode_execution_config,\n\u001b[0;32m     64\u001b[0m         llm_config\u001b[39m=\u001b[39mllm_config,\n\u001b[0;32m     65\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m     66\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\MindExpander\\Documents\\GitHub\\autogen\\.venv\\lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:115\u001b[0m, in \u001b[0;36mConversableAgent.__init__\u001b[1;34m(self, name, system_message, is_termination_msg, max_consecutive_auto_reply, human_input_mode, function_map, code_execution_config, llm_config, default_auto_reply)\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(llm_config, \u001b[39mdict\u001b[39m):\n\u001b[0;32m    114\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm_config\u001b[39m.\u001b[39mupdate(llm_config)\n\u001b[1;32m--> 115\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient \u001b[39m=\u001b[39m OpenAIWrapper(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mllm_config)\n\u001b[0;32m    117\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_code_execution_config \u001b[39m=\u001b[39m {} \u001b[39mif\u001b[39;00m code_execution_config \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m code_execution_config\n\u001b[0;32m    118\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhuman_input_mode \u001b[39m=\u001b[39m human_input_mode\n",
      "File \u001b[1;32mc:\\Users\\MindExpander\\Documents\\GitHub\\autogen\\.venv\\lib\\site-packages\\autogen\\oai\\client.py:74\u001b[0m, in \u001b[0;36mOpenAIWrapper.__init__\u001b[1;34m(self, config_list, **base_config)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39mif\u001b[39;00m config_list:\n\u001b[0;32m     73\u001b[0m     config_list \u001b[39m=\u001b[39m [config\u001b[39m.\u001b[39mcopy() \u001b[39mfor\u001b[39;00m config \u001b[39min\u001b[39;00m config_list]  \u001b[39m# make a copy before modifying\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_clients \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_client(config, openai_config) \u001b[39mfor\u001b[39;00m config \u001b[39min\u001b[39;00m config_list]  \u001b[39m# could modify the config\u001b[39;00m\n\u001b[0;32m     75\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_config_list \u001b[39m=\u001b[39m [\n\u001b[0;32m     76\u001b[0m         {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mextra_kwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m config\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopenai_kwargs}}\n\u001b[0;32m     77\u001b[0m         \u001b[39mfor\u001b[39;00m config \u001b[39min\u001b[39;00m config_list\n\u001b[0;32m     78\u001b[0m     ]\n\u001b[0;32m     79\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\MindExpander\\Documents\\GitHub\\autogen\\.venv\\lib\\site-packages\\autogen\\oai\\client.py:74\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39mif\u001b[39;00m config_list:\n\u001b[0;32m     73\u001b[0m     config_list \u001b[39m=\u001b[39m [config\u001b[39m.\u001b[39mcopy() \u001b[39mfor\u001b[39;00m config \u001b[39min\u001b[39;00m config_list]  \u001b[39m# make a copy before modifying\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_clients \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_client(config, openai_config) \u001b[39mfor\u001b[39;00m config \u001b[39min\u001b[39;00m config_list]  \u001b[39m# could modify the config\u001b[39;00m\n\u001b[0;32m     75\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_config_list \u001b[39m=\u001b[39m [\n\u001b[0;32m     76\u001b[0m         {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mextra_kwargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m config\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopenai_kwargs}}\n\u001b[0;32m     77\u001b[0m         \u001b[39mfor\u001b[39;00m config \u001b[39min\u001b[39;00m config_list\n\u001b[0;32m     78\u001b[0m     ]\n\u001b[0;32m     79\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\MindExpander\\Documents\\GitHub\\autogen\\.venv\\lib\\site-packages\\autogen\\oai\\client.py:135\u001b[0m, in \u001b[0;36mOpenAIWrapper._client\u001b[1;34m(self, config, openai_config)\u001b[0m\n\u001b[0;32m    133\u001b[0m openai_config \u001b[39m=\u001b[39m {\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mopenai_config, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m config\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopenai_kwargs}}\n\u001b[0;32m    134\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_for_azure(openai_config, config)\n\u001b[1;32m--> 135\u001b[0m client \u001b[39m=\u001b[39m OpenAI(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mopenai_config)\n\u001b[0;32m    136\u001b[0m \u001b[39mreturn\u001b[39;00m client\n",
      "File \u001b[1;32mc:\\Users\\MindExpander\\Documents\\GitHub\\autogen\\.venv\\lib\\site-packages\\openai\\_client.py:93\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[1;34m(self, api_key, organization, base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[0;32m     91\u001b[0m     api_key \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39menviron\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mOPENAI_API_KEY\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     92\u001b[0m \u001b[39mif\u001b[39;00m api_key \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 93\u001b[0m     \u001b[39mraise\u001b[39;00m OpenAIError(\n\u001b[0;32m     94\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     95\u001b[0m     )\n\u001b[0;32m     96\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key \u001b[39m=\u001b[39m api_key\n\u001b[0;32m     98\u001b[0m \u001b[39mif\u001b[39;00m organization \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "assistant_for_student = autogen.AssistantAgent(\n",
    "    name=\"assistant_for_student\",\n",
    "    system_message=\"You are a helpful assistant. Reply TERMINATE when the task is done.\",\n",
    "    llm_config={\n",
    "        \"timeout\": 600,\n",
    "        \"cache_seed\": 42,\n",
    "        \"config_list\": config_list,\n",
    "        \"temperature\": 0,\n",
    "        \"functions\": [\n",
    "            {\n",
    "                \"name\": \"ask_expert\",\n",
    "                \"description\": \"ask expert when you can't solve the problem satisfactorily.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"message\": {\n",
    "                            \"type\": \"string\",\n",
    "                            \"description\": \"question to ask expert. Ensure the question includes enough context, such as the code and the execution result. The expert does not know the conversation between you and the user unless you share the conversation with the expert.\",\n",
    "                        },\n",
    "                    },\n",
    "                    \"required\": [\"message\"],\n",
    "                },\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "\n",
    "student = autogen.UserProxyAgent(\n",
    "    name=\"student\",\n",
    "    human_input_mode=\"TERMINATE\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    code_execution_config={\"work_dir\": \"student\"},\n",
    "    function_map={\"ask_expert\": ask_expert},\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform a task\n",
    "\n",
    "We invoke the `initiate_chat()` method of the student proxy agent to start the conversation. When you run the cell below, you will be prompted to provide feedback after the assistant agent sends a \"TERMINATE\" signal at the end of the message. The conversation will finish if you don't provide any feedback (by pressing Enter directly). Before the \"TERMINATE\" signal, the student proxy agent will try to execute the code suggested by the assistant agent on behalf of the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mstudent\u001b[0m (to assistant_for_student):\n",
      "\n",
      "Find $a + b + c$, given that $x+y \\neq -1$ and \n",
      "\\begin{align}\n",
      "\tax + by + c & = x + 7,\\\n",
      "\ta + bx + cy & = 2x + 6y,\\\n",
      "\tay + b + cx & = 4x + y.\n",
      "\\end{align}.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Completions.create() got an unexpected keyword argument 'api_base'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\MindExpander\\Documents\\GitHub\\autogen\\notebook\\agentchat_two_users.ipynb Cell 11\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MindExpander/Documents/GitHub/autogen/notebook/agentchat_two_users.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# the assistant receives a message from the student, which contains the task description\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/MindExpander/Documents/GitHub/autogen/notebook/agentchat_two_users.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m student\u001b[39m.\u001b[39;49minitiate_chat(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MindExpander/Documents/GitHub/autogen/notebook/agentchat_two_users.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     assistant_for_student,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MindExpander/Documents/GitHub/autogen/notebook/agentchat_two_users.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     message\u001b[39m=\u001b[39;49m\u001b[39m\"\"\"\u001b[39;49m\u001b[39mFind $a + b + c$, given that $x+y \u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\u001b[39mneq -1$ and \u001b[39;49m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MindExpander/Documents/GitHub/autogen/notebook/agentchat_two_users.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m\\\\\u001b[39;49;00m\u001b[39mbegin\u001b[39;49m\u001b[39m{align}\u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MindExpander/Documents/GitHub/autogen/notebook/agentchat_two_users.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m\tax + by + c & = x + 7,\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MindExpander/Documents/GitHub/autogen/notebook/agentchat_two_users.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m\ta + bx + cy & = 2x + 6y,\u001b[39;49m\u001b[39m\\\\\u001b[39;49;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MindExpander/Documents/GitHub/autogen/notebook/agentchat_two_users.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m\tay + b + cx & = 4x + y.\u001b[39;49m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/MindExpander/Documents/GitHub/autogen/notebook/agentchat_two_users.ipynb#X13sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m\\\\\u001b[39;49;00m\u001b[39mend\u001b[39;49m\u001b[39m{align}\u001b[39;49;00m\u001b[39m.\u001b[39;49m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MindExpander/Documents/GitHub/autogen/notebook/agentchat_two_users.ipynb#X13sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/MindExpander/Documents/GitHub/autogen/notebook/agentchat_two_users.ipynb#X13sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\MindExpander\\Documents\\GitHub\\autogen\\.venv\\lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:540\u001b[0m, in \u001b[0;36mConversableAgent.initiate_chat\u001b[1;34m(self, recipient, clear_history, silent, **context)\u001b[0m\n\u001b[0;32m    526\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Initiate a chat with the recipient agent.\u001b[39;00m\n\u001b[0;32m    527\u001b[0m \n\u001b[0;32m    528\u001b[0m \u001b[39mReset the consecutive auto reply counter.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[39m        \"message\" needs to be provided if the `generate_init_message` method is not overridden.\u001b[39;00m\n\u001b[0;32m    538\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    539\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_chat(recipient, clear_history)\n\u001b[1;32m--> 540\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_init_message(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcontext), recipient, silent\u001b[39m=\u001b[39;49msilent)\n",
      "File \u001b[1;32mc:\\Users\\MindExpander\\Documents\\GitHub\\autogen\\.venv\\lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:340\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[1;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[0;32m    338\u001b[0m valid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_append_oai_message(message, \u001b[39m\"\u001b[39m\u001b[39massistant\u001b[39m\u001b[39m\"\u001b[39m, recipient)\n\u001b[0;32m    339\u001b[0m \u001b[39mif\u001b[39;00m valid:\n\u001b[1;32m--> 340\u001b[0m     recipient\u001b[39m.\u001b[39;49mreceive(message, \u001b[39mself\u001b[39;49m, request_reply, silent)\n\u001b[0;32m    341\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    342\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    343\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMessage can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    344\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\MindExpander\\Documents\\GitHub\\autogen\\.venv\\lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:471\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[1;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[0;32m    469\u001b[0m \u001b[39mif\u001b[39;00m request_reply \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mor\u001b[39;00m request_reply \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreply_at_receive[sender] \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[0;32m    470\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 471\u001b[0m reply \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_reply(messages\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchat_messages[sender], sender\u001b[39m=\u001b[39;49msender)\n\u001b[0;32m    472\u001b[0m \u001b[39mif\u001b[39;00m reply \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    473\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(reply, sender, silent\u001b[39m=\u001b[39msilent)\n",
      "File \u001b[1;32mc:\\Users\\MindExpander\\Documents\\GitHub\\autogen\\.venv\\lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:883\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[1;34m(self, messages, sender, exclude)\u001b[0m\n\u001b[0;32m    881\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m    882\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[39m\"\u001b[39m\u001b[39mtrigger\u001b[39m\u001b[39m\"\u001b[39m], sender):\n\u001b[1;32m--> 883\u001b[0m     final, reply \u001b[39m=\u001b[39m reply_func(\u001b[39mself\u001b[39;49m, messages\u001b[39m=\u001b[39;49mmessages, sender\u001b[39m=\u001b[39;49msender, config\u001b[39m=\u001b[39;49mreply_func_tuple[\u001b[39m\"\u001b[39;49m\u001b[39mconfig\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m    884\u001b[0m     \u001b[39mif\u001b[39;00m final:\n\u001b[0;32m    885\u001b[0m         \u001b[39mreturn\u001b[39;00m reply\n",
      "File \u001b[1;32mc:\\Users\\MindExpander\\Documents\\GitHub\\autogen\\.venv\\lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:615\u001b[0m, in \u001b[0;36mConversableAgent.generate_oai_reply\u001b[1;34m(self, messages, sender, config)\u001b[0m\n\u001b[0;32m    612\u001b[0m     messages \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_oai_messages[sender]\n\u001b[0;32m    614\u001b[0m \u001b[39m# TODO: #1143 handle token limit exceeded error\u001b[39;00m\n\u001b[1;32m--> 615\u001b[0m response \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m    616\u001b[0m     context\u001b[39m=\u001b[39;49mmessages[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49mpop(\u001b[39m\"\u001b[39;49m\u001b[39mcontext\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m), messages\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_oai_system_message \u001b[39m+\u001b[39;49m messages\n\u001b[0;32m    617\u001b[0m )\n\u001b[0;32m    618\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m, client\u001b[39m.\u001b[39mextract_text_or_function_call(response)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\MindExpander\\Documents\\GitHub\\autogen\\.venv\\lib\\site-packages\\autogen\\oai\\client.py:242\u001b[0m, in \u001b[0;36mOpenAIWrapper.create\u001b[1;34m(self, **config)\u001b[0m\n\u001b[0;32m    240\u001b[0m completions \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39mchat\u001b[39m.\u001b[39mcompletions \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mmessages\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m params \u001b[39melse\u001b[39;00m client\u001b[39m.\u001b[39mcompletions\n\u001b[0;32m    241\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 242\u001b[0m     response \u001b[39m=\u001b[39m completions\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[0;32m    243\u001b[0m \u001b[39mexcept\u001b[39;00m APIError:\n\u001b[0;32m    244\u001b[0m     logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mconfig \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m failed\u001b[39m\u001b[39m\"\u001b[39m, exc_info\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\MindExpander\\Documents\\GitHub\\autogen\\.venv\\lib\\site-packages\\openai\\_utils\\_utils.py:299\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    297\u001b[0m             msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMissing required argument: \u001b[39m\u001b[39m{\u001b[39;00mquote(missing[\u001b[39m0\u001b[39m])\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    298\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 299\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: Completions.create() got an unexpected keyword argument 'api_base'"
     ]
    }
   ],
   "source": [
    "# the assistant receives a message from the student, which contains the task description\n",
    "student.initiate_chat(\n",
    "    assistant_for_student,\n",
    "    message=\"\"\"Find $a + b + c$, given that $x+y \\\\neq -1$ and \n",
    "\\\\begin{align}\n",
    "\tax + by + c & = x + 7,\\\\\n",
    "\ta + bx + cy & = 2x + 6y,\\\\\n",
    "\tay + b + cx & = 4x + y.\n",
    "\\\\end{align}.\n",
    "\"\"\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the assistant needs to consult the expert, it suggests a function call to `ask_expert`. When this happens, a line like the following will be displayed:\n",
    "\n",
    "***** Suggested function Call: ask_expert *****\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "2d910cfd2d2a4fc49fc30fbbdc5576a7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "454146d0f7224f038689031002906e6f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e4ae2b6f5a974fd4bafb6abb9d12ff26",
        "IPY_MODEL_577e1e3cc4db4942b0883577b3b52755",
        "IPY_MODEL_b40bdfb1ac1d4cffb7cefcb870c64d45"
       ],
       "layout": "IPY_MODEL_dc83c7bff2f241309537a8119dfc7555",
       "tabbable": null,
       "tooltip": null
      }
     },
     "577e1e3cc4db4942b0883577b3b52755": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2d910cfd2d2a4fc49fc30fbbdc5576a7",
       "max": 1,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_74a6ba0c3cbc4051be0a83e152fe1e62",
       "tabbable": null,
       "tooltip": null,
       "value": 1
      }
     },
     "6086462a12d54bafa59d3c4566f06cb2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "74a6ba0c3cbc4051be0a83e152fe1e62": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7d3f3d9e15894d05a4d188ff4f466554": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b40bdfb1ac1d4cffb7cefcb870c64d45": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f1355871cc6f4dd4b50d9df5af20e5c8",
       "placeholder": "​",
       "style": "IPY_MODEL_ca245376fd9f4354af6b2befe4af4466",
       "tabbable": null,
       "tooltip": null,
       "value": " 1/1 [00:00&lt;00:00, 44.69it/s]"
      }
     },
     "ca245376fd9f4354af6b2befe4af4466": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "dc83c7bff2f241309537a8119dfc7555": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e4ae2b6f5a974fd4bafb6abb9d12ff26": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6086462a12d54bafa59d3c4566f06cb2",
       "placeholder": "​",
       "style": "IPY_MODEL_7d3f3d9e15894d05a4d188ff4f466554",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "f1355871cc6f4dd4b50d9df5af20e5c8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
